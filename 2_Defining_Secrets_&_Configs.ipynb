{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sg-56/DLT_Workshop/blob/main/2_Defining_Secrets_%26_Configs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **Defining Secrets & Configs** ðŸ¤«ðŸ”©\n",
        "\n",
        "**Here, you will learn or brush up on how to:**\n",
        "- Add values to `secrets.toml` or `config.toml`\n",
        "- Use environment variables to handle both secrets & configs"
      ],
      "metadata": {
        "id": "pTAeTdoKJHZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##  **(0) Add values to `secrets.toml` or `config.toml`**\n"
      ],
      "metadata": {
        "id": "l7Y1oCAvJ79I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Please note that Colab is not well-suited for using `secrets.toml` or `config.toml` files. As a result, these sections will provide instructions rather than code cells, detailing how to use them in a local environment. You should test this functionality on your own machine. For Colab, it is recommended to use environment variables instead."
      ],
      "metadata": {
        "id": "mNzCp5BGpDSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `secrets.toml` file - along with the `config.toml` file - should be stored in the `.dlt` directory where your pipeline code is located:\n",
        "\n",
        "```\n",
        "/your_project_directory\n",
        "â”‚\n",
        "â”œâ”€â”€ .dlt\n",
        "â”‚   â”œâ”€â”€ secrets.toml\n",
        "â”‚   â””â”€â”€ config.toml\n",
        "â”‚\n",
        "â””â”€â”€ my_pipeline.py\n",
        "```"
      ],
      "metadata": {
        "id": "N3LJ7NQDqTCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say your `my_pipeline.py` looks something like this:\n",
        "\n",
        "```python\n",
        "import dlt\n",
        "from dlt.sources.helpers import requests\n",
        "\n",
        "\n",
        "def pagination(url):\n",
        "    while True:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        yield response.json()\n",
        "\n",
        "        # Get next page\n",
        "        if \"next\" not in response.links:\n",
        "            break\n",
        "        url = response.links[\"next\"][\"url\"]\n",
        "\n",
        "\n",
        "@dlt.resource(table_name=\"issues\")\n",
        "def get_issues():\n",
        "    url = \"https://api.github.com/repos/dlt-hub/dlt/issues?per_page=100\"\n",
        "    yield pagination(url)\n",
        "\n",
        "# Rest of the pipeline code\n",
        "```"
      ],
      "metadata": {
        "id": "Ra4FEWkAr8Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary rate limit for unauthenticated requests is 60 requests per hour. Sooner or later you will face rate limit errors. You can use a personal access token to make API requests. This will increase the rate to 5,000 requests per hour."
      ],
      "metadata": {
        "id": "AonppyYosOm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do that you would first add your access token to `secrets.toml`:\n",
        "\n",
        "```\n",
        "# .dlt/secrets.toml\n",
        "\n",
        "access_token = \"your_access_token\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6bTyl229sadQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you would let the `dlt` resource access it with `dlt.secrets.value` the following way:\n",
        "\n",
        "```python\n",
        "import dlt\n",
        "from dlt.sources.helpers import requests\n",
        "\n",
        "\n",
        "def pagination(url, access_token):\n",
        "    while True:\n",
        "        response = requests.get(url, headers={\"Authorization\": f\"Bearer {access_token}\"})\n",
        "        response.raise_for_status()\n",
        "        yield response.json()\n",
        "\n",
        "        # Get next page\n",
        "        if \"next\" not in response.links:\n",
        "            break\n",
        "        url = response.links[\"next\"][\"url\"]\n",
        "\n",
        "\n",
        "@dlt.resource(table_name=\"issues\")\n",
        "def get_issues(\n",
        "    access_token=dlt.secrets.value\n",
        "):\n",
        "    url = \"https://api.github.com/repos/dlt-hub/dlt/issues?per_page=100\"\n",
        "    yield pagination(url, access_token)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "xDJmIUahs2nT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configs are defined in a similar way but are accessed using `dlt.config.value`. However, since configuration variables are internally managed by `dlt`, it is unlikely that you would need to explicitly use `dlt.config.value` in most cases."
      ],
      "metadata": {
        "id": "H-wNVUqfuD37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##  **(0) Use environment variables**\n"
      ],
      "metadata": {
        "id": "gUM3JCeMujEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install `dlt` with DuckDB as destination:"
      ],
      "metadata": {
        "id": "oZQwNSQQwdL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install \"dlt[duckdb]\""
      ],
      "metadata": {
        "id": "ahoy-AWOwgRt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an environment variable for your access token. If you have your token ready in Colab, you can directly use it:"
      ],
      "metadata": {
        "id": "-azxlrmCuvNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the access token from user input\n",
        "access_token = userdata.get('ACCESS_TOKEN')\n",
        "\n",
        "# Set it as an environment variable\n",
        "os.environ['ACCESS_TOKEN'] = access_token"
      ],
      "metadata": {
        "id": "iIWXRnPquhB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's reduce the number of per page results to 1, so that we can see that the unauthorized rate limit of 60 isn't an issue since we're using an access token:"
      ],
      "metadata": {
        "id": "mAivoWcVwE5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dlt\n",
        "from dlt.sources.helpers import requests\n",
        "\n",
        "\n",
        "def pagination(url, access_token):\n",
        "    while True:\n",
        "        response = requests.get(url, headers={\"Authorization\": f\"Bearer {access_token}\"})\n",
        "        response.raise_for_status()\n",
        "        yield response.json()\n",
        "\n",
        "        # Get next page\n",
        "        if \"next\" not in response.links:\n",
        "            break\n",
        "        url = response.links[\"next\"][\"url\"]\n",
        "\n",
        "\n",
        "@dlt.resource(table_name=\"issues\")\n",
        "def get_issues(\n",
        "    access_token=dlt.secrets.value\n",
        "):\n",
        "    url = \"https://api.github.com/repos/dlt-hub/dlt/issues?per_page=1\" # Set per page to 1\n",
        "    yield pagination(url, access_token)"
      ],
      "metadata": {
        "id": "Kw6L0Lqov7Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a pipeline:"
      ],
      "metadata": {
        "id": "KJNWhEZ7u422"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = dlt.pipeline(\n",
        "    pipeline_name=\"my_pipeline\",\n",
        "    destination=\"duckdb\"\n",
        ")"
      ],
      "metadata": {
        "id": "FJREnDkRwq4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the pipeline:"
      ],
      "metadata": {
        "id": "GTftQjX9wvwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_info = pipeline.run(\n",
        "    get_issues\n",
        ")\n",
        "print(load_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N3u62xPww1x",
        "outputId": "3d9449f1-fc4b-471f-910a-d94ddfe2b86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline my_pipeline load step completed in 1.33 seconds\n",
            "1 load package(s) were loaded to destination duckdb and into dataset my_pipeline_dataset\n",
            "The duckdb destination used duckdb:////content/my_pipeline.duckdb location to store data\n",
            "Load package 1726589501.8991365 is LOADED and contains no failed jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check how many rows of data/requests were made:"
      ],
      "metadata": {
        "id": "2MCwfOPww8qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline.last_trace.last_normalize_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlkzS-BOxEX3",
        "outputId": "e1ba91fe-4910-460f-e710-01709b585557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized data for the following tables:\n",
            "- _dlt_pipeline_state: 1 row(s)\n",
            "- issues: 167 row(s)\n",
            "- issues__labels: 122 row(s)\n",
            "- issues__assignees: 62 row(s)\n",
            "- issues__performed_via_github_app__events: 25 row(s)\n",
            "\n",
            "Load package 1726589501.8991365 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can also set `dlt.secrets` with environment variables:"
      ],
      "metadata": {
        "id": "vxpWb5gLxR4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlt.secrets[\"access_token\"] = userdata.get('ACCESS_TOKEN')"
      ],
      "metadata": {
        "id": "v2RwZyIMxaHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redefine the resource:"
      ],
      "metadata": {
        "id": "qw_tYvllxdBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dlt\n",
        "from dlt.sources.helpers import requests\n",
        "\n",
        "\n",
        "def pagination(url, access_token):\n",
        "    while True:\n",
        "        response = requests.get(url, headers={\"Authorization\": f\"Bearer {access_token}\"})\n",
        "        response.raise_for_status()\n",
        "        yield response.json()\n",
        "\n",
        "        # Get next page\n",
        "        if \"next\" not in response.links:\n",
        "            break\n",
        "        url = response.links[\"next\"][\"url\"]\n",
        "\n",
        "\n",
        "@dlt.resource(table_name=\"issues\")\n",
        "def get_issues(\n",
        "    access_token=dlt.secrets.value\n",
        "):\n",
        "    url = \"https://api.github.com/repos/dlt-hub/dlt/issues?per_page=1\" # Set per page to 1\n",
        "    yield pagination(url, access_token)"
      ],
      "metadata": {
        "id": "zGroVu_lxebj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the pipeline again:"
      ],
      "metadata": {
        "id": "leiybSKwx3xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_info = pipeline.run(\n",
        "    get_issues\n",
        ")\n",
        "print(load_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "claNDMmDx439",
        "outputId": "49292a2f-63a9-44ea-cefe-db258888a6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline my_pipeline load step completed in 1.16 seconds\n",
            "1 load package(s) were loaded to destination duckdb and into dataset my_pipeline_dataset\n",
            "The duckdb destination used duckdb:////content/my_pipeline.duckdb location to store data\n",
            "Load package 1726589568.2547753 is LOADED and contains no failed jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check how many rows of data/requests were made:"
      ],
      "metadata": {
        "id": "6LoRG30zyFUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline.last_trace.last_normalize_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgZ0UwAnyG8B",
        "outputId": "6d26e83d-a1ab-4662-e2d6-8f0d6ba22673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized data for the following tables:\n",
            "- issues: 184 row(s)\n",
            "- issues__assignees: 78 row(s)\n",
            "- issues__labels: 150 row(s)\n",
            "- issues__performed_via_github_app__events: 25 row(s)\n",
            "\n",
            "Load package 1726069850.8036563 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The naming convention for environment variables in `dlt` follows a specific pattern. All names are capitalized and sections are separated with double underscores __ . For example, if you have a config or secret variable named `destination.filesystem` in your TOML file, it would become `DESTINATION__FILESYSTEM` in your environment variables. Similarly, if you have a nested structure like `destination.filesystem.bucket_url`, it would become `DESTINATION__FILESYSTEM__BUCKET_URL` in your environment variables.\n",
        ">\n",
        ">\n",
        ">```\n",
        "[destination.filesystem]\n",
        "bucket_url = 'random_ul'\n",
        "```\n",
        ">\n",
        ">```\n",
        "DESTINATION__FILESYSTEM__BUCKET_URL\n",
        "```"
      ],
      "metadata": {
        "id": "rSlTyddUz11z"
      }
    }
  ]
}